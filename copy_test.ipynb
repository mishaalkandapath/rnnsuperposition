{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Union\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import plotly.express as px\n",
    "\n",
    "from train import evaluate_model_copy, CopyConfig, inference_generate\n",
    "from rnn import RNN, GRULayer\n",
    "\n",
    "torch.manual_seed(8)\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): GRULayer(\n",
      "    (input_to_reset): Linear(in_features=31, out_features=256, bias=False)\n",
      "    (hidden_to_reset): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (input_to_update): Linear(in_features=31, out_features=256, bias=False)\n",
      "    (hidden_to_update): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (input_to_new): Linear(in_features=31, out_features=256, bias=False)\n",
      "    (hidden_to_new): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (1): Linear(in_features=256, out_features=30, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1024 achieved 1.0 no issues, 256 took some tries and the best is at: \"run_256_fixed_lower_wdlr_ctd\". \n",
    "d_hidden = 256\n",
    "run_name = \"run_256_fixed_lower_wdlr_ctd\"\n",
    "copy_test_cfg = CopyConfig(run_name=run_name, d_hidden=d_hidden, gru=True)\n",
    "\n",
    "model = RNN(31, copy_test_cfg.d_hidden, out_size=30, \n",
    "            out_act= lambda x: x, use_gru=copy_test_cfg.gru)\n",
    "model.load_state_dict(torch.load(f\"models/copy_train/{copy_test_cfg.run_name}/{copy_test_cfg.run_name}.ckpt\", weights_only=True, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:09<00:00, 72.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00040266723594573897, 1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_copy(copy_test_cfg, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot gru gate movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_update_gate_heatmap(model, sequence, loss_mask, layer=-1):\n",
    "    # Run forward with gate recording enabled\n",
    "    outputs, h_t, r_t_all, z_t_all = inference_generate(model, sequence, \n",
    "                                                        discrete=True,\n",
    "                                                        record_gates=True)\n",
    "\n",
    "\n",
    "    layers, batch_size, seq_len, hidden_size = z_t_all.shape\n",
    "    if layer > 0:\n",
    "        z_t_all, r_t_all = z_t_all[layer].unsqueeze(0), r_t_all[layer].unsqueeze(0)\n",
    "\n",
    "\n",
    "    mask = loss_mask.unsqueeze(0).unsqueeze(-1) # (1, b, l, 1)\n",
    "    z_t_all_masked = z_t_all * mask  # invalid positions become 0\n",
    "\n",
    "     # Count valid positions per layer, timestep, and hidden unit across batches\n",
    "    valid_counts = mask.sum(dim=1)  # sum over batch dimension, shape (1, seq_len, 1)\n",
    "    valid_counts = valid_counts.clamp(min=1)  # avoid division by zero\n",
    "    \n",
    "    # Sum over batches to get total activations per layer, timestep, hidden unit\n",
    "    z_t_sum = z_t_all_masked.sum(dim=1)  # sum over batch dimension, shape (layers, seq_len, hidden_size)\n",
    "    \n",
    "    # Average by dividing sum by counts of valid batches\n",
    "    # Note: valid_counts shape (1, seq_len, 1) broadcasts over layers and hidden_size\n",
    "    z_t_avg = z_t_sum / valid_counts\n",
    "\n",
    "    # Plot one heatmap per layer\n",
    "    for layer in range(layers):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        # Transpose so x axis = time steps, y axis = hidden units\n",
    "        plt.imshow(z_t_avg[layer].T.cpu(), aspect='auto', cmap='viridis', vmin=0, vmax=1)\n",
    "        plt.colorbar(label=\"Update gate z_t\")\n",
    "        plt.xlabel(\"Time step\")\n",
    "        plt.ylabel(\"Hidden unit\")\n",
    "        plt.title(f\"Update Gate Activations for Layer {layer}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to viz:\n",
    "test_dataset = torch.load(f\"data/copy_test/{copy_test_cfg.run_name}.pt\")\n",
    "batches = [1]\n",
    "test_data = [test_dataset[batch] for batch in batches]\n",
    "test_data, test_loss_masks = zip(*test_data)\n",
    "test_data, test_loss_masks = torch.stack(test_data), torch.stack(test_loss_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplot_update_gate_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loss_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mplot_update_gate_heatmap\u001b[39m\u001b[34m(model, sequence, loss_mask, layer)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_update_gate_heatmap\u001b[39m(model, sequence, loss_mask, layer=-\u001b[32m1\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Run forward with gate recording enabled\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     outputs, h_t, r_t_all, z_t_all = \u001b[43minference_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                                        \u001b[49m\u001b[43mdiscrete\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                                                        \u001b[49m\u001b[43mrecord_gates\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     layers, batch_size, seq_len, hidden_size = z_t_all.shape\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m layer > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/w/150/lambda_squad/misc/rnnsuperposition/train.py:177\u001b[39m, in \u001b[36minference_generate\u001b[39m\u001b[34m(model, input_data, discrete, record_gates)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m record_gates:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m         rnn_outputs, final_hiddens, r_t_seq, z_t_seq = model(input_with_delim)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    179\u001b[39m         rnn_outputs, final_hiddens = model(input_with_delim)\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "plot_update_gate_heatmap(model, test_data, test_loss_masks)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
